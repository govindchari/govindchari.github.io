<!DOCTYPE html>
<!-- _layouts/distill.html --><html>
  <head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">    <!-- Metadata, OpenGraph and Schema.org -->
    

    <!-- Standard metadata -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>Solving the Lasso Problem | Govind M Chari</title>
    <meta name="author" content="Govind M Chari">
    <meta name="description" content="Comparing optimization algorithms for Lasso">
    <meta name="keywords" content="gnc, optimization, phd">


    <!-- Bootstrap & MDB -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous">

    <!-- Fonts & Icons -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous">
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700%7CRoboto+Slab:100,300,400,500,700%7CMaterial+Icons">

    <!-- Code Syntax Highlighting -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light">

    <!-- Styles -->
    
    <link rel="shortcut icon" href="/assets/img/favicon.png">
    
    <link rel="stylesheet" href="/assets/css/main.css">
    <link rel="canonical" href="http://localhost:4000/blog/2023/solving-lasso/">
    
    <!-- Dark Mode -->
    
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark">

    <script src="/assets/js/theme.js"></script>
    <script src="/assets/js/dark_mode.js"></script>
    


    <!-- jQuery -->
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>

    <!-- MathJax -->
  <script type="text/javascript">
    window.MathJax = {
      tex: {
        tags: 'ams'
      }
    };
  </script>
  <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
  <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>

    <!-- Distill js -->
    <script src="/assets/js/distillpub/template.v2.js"></script>
    <script src="/assets/js/distillpub/transforms.v2.js"></script>
    <script src="/assets/js/distillpub/overrides.js"></script>
    
  </head>

  <body>
<d-front-matter>
    <script async type="text/json">{
      "title": "Solving the Lasso Problem",
      "description": "Comparing optimization algorithms for Lasso",
      "published": "October 25, 2023",
      "authors": [
        {
          "author": "Govind Chari",
          "authorURL": "https://govindchari.com/",
          "affiliations": [
            {
              "name": "University of Washington Autonomous Controls Lab",
              "url": ""
            }
          ]
        }
        
      ],
      "katex": {
        "delimiters": [
          {
            "left": "$",
            "right": "$",
            "display": false
          },
          {
            "left": "$$",
            "right": "$$",
            "display": true
          }
        ]
      }
    }</script>
  </d-front-matter>

  

    <!-- Header -->
    <header>

      <!-- Nav Bar -->
      <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
        <div class="container">
          <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">Govind </span>M Chari</a>
          <!-- Navbar Toggle -->
          <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar top-bar"></span>
            <span class="icon-bar middle-bar"></span>
            <span class="icon-bar bottom-bar"></span>
          </button>

          <div class="collapse navbar-collapse text-right" id="navbarNav">
            <ul class="navbar-nav ml-auto flex-nowrap">

              <!-- About -->
              <li class="nav-item ">
                <a class="nav-link" href="/">about</a>
              </li>
              
              <!-- Blog -->
              <li class="nav-item active">
                <a class="nav-link" href="/blog/">blog<span class="sr-only">(current)</span></a>
              </li>

              <!-- Other pages -->
              <li class="nav-item ">
                <a class="nav-link" href="/publications/">publications</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/projects/">projects</a>
              </li>

              <!-- Toogle theme mode -->
              <li class="toggle-container">
                <button id="light-toggle" title="Change theme">
                  <i class="fas fa-moon"></i>
                  <i class="fas fa-sun"></i>
                </button>
              </li>
            </ul>
          </div>
        </div>
      </nav>

      <!-- Scrolling Progress Bar -->
      <progress id="progress" value="0">
        <div class="progress-container">
          <span class="progress-bar"></span>
        </div>
      </progress>
    </header>


    <!-- Content -->
    <div class="post distill">

      <d-title>
        <h1>Solving the Lasso Problem</h1>
        <p>Comparing optimization algorithms for Lasso</p>
      </d-title>

      <d-byline></d-byline>

      <d-article>
        <d-contents>
          <nav class="l-text figcaption">
          <h3>Contents</h3>
            <div><a href="#introduction">Introduction</a></div>
            <div><a href="#reformulating-as-quadratic-program">Reformulating as Quadratic Program</a></div>
            <div><a href="#ista">ISTA</a></div>
            <div><a href="#fista">FISTA</a></div>
            <div><a href="#admm">ADMM</a></div>
            <div><a href="#results">Results</a></div>
            
          </nav>
        </d-contents>

        <h2 id="introduction">Introduction</h2>
<p>Lasso regression is and important regularization technique for linear regression that can also perform variable selection. What this means is that solutions to the lasso problem tend to be sparse (contain zeros) which allows us to rule out certain independent variables in our model. A great resource to familiarize yourself with lasso is <a href="https://www.youtube.com/watch?v=GaXfqoLR_yI&amp;ab_channel=SteveBrunton" rel="external nofollow noopener" target="_blank">this video</a>.</p>

<p>Lasso is of incredible importance in statistics, signal processing, compressed sensing, and image processing. In this post we will look at a variety of optimization technique for solving the lasso problem.</p>

<p>The lasso optimization problem is an unconstrained optimization problem which can be written as follows:</p>

\[\begin{split}
    \underset{x}{\text{minimize}} 
    \quad &amp; \frac{1}{2}\|Ax-b\|_2^2 + \lambda \|x\|_1 \\
\end{split}\]

<p>where $A \in \mathbb{R}^{m \times n}$</p>

<p>A first thought to solve this problem might be gradient descent, however the objective function is non-smooth (due to the l1 penalty), so we cannot use gradient descent.
A second thought is to use subgradient descent, which is a generalization of gradient descent to non-smooth functions. This would work, but subgradient descent has an extremely slow worst-case convergence rate of $\mathcal{O}(1 / \sqrt{t})$ (meaning you need four times the iterations to double the accuracy) so we will look at better algorithms.</p>

<h2 id="reformulating-as-quadratic-program">Reformulating as Quadratic Program</h2>
<p>One of the easiest things to do would be reformulating this problem as a Quadratic Program (QP) as follows:</p>

\[\begin{split}
    \underset{x}{\text{minimize}} 
    \quad &amp; \frac{1}{2}\|Ax-b\|_2^2 + \lambda \sum_{i=1}^n t_i \\
    \text{subject to} 
    \quad &amp; -t_i \leq x_i \leq t_i \quad \forall i \in [1,n]
\end{split}\]

<p>To see how this was done reference the <a href="https://docs.mosek.com/modeling-cookbook/linear.html#the-ell-1-norm" rel="external nofollow noopener" target="_blank">Mosek Modeling Cookbook</a></p>

<p>We can then feed this into a QP solver such as OSQP and then get an answer. This works, but it feels wasteful to turn an unconstrained problem into a constrained one and then use a generic QP solver. There should be better algorithms that exploit the structure of our problem where we have a smooth plus a non-smooth term.</p>

<h2 id="ista">ISTA</h2>
<p>ISTA or iterative shrinking threshold algorithm is an application of the proximal gradient method to the Lasso problem.</p>

<p>The proximal gradient method solves problems of the following form, where $f$ is differentiable</p>

\[\begin{split}
    \underset{x}{\text{minimize}} 
    \quad &amp; f(x) + g(x) \\
\end{split}\]

<p>The algorithm looks as follows:</p>

\[x_{k+1} = \boldsymbol{\text{prox}}_{\eta g}(x_k - \eta \nabla f(x_k))\]

<p>where $\eta$ is the gradient descent stepsize for $f$ which will be the inverse of the Lipschitz constant of $f$.</p>

<p>The proximal operator $\boldsymbol{\text{prox}}_{\eta g}$ is a generalization of the projection operation and is defined as follows</p>

\[\boldsymbol{\text{prox}}_{\eta f}(v) = \underset{x}{\text{argmin}} \left(f(x) + \frac{1}{2\eta}\|x-v\|_2^2\right)\]

<p>You can think of the proximal operator as returning a point which balances minimizing the function and staying close to the current point. The proximal operator for many function are well known in closed form. For more information on proximal operators and algorithms using proximal operators, refer to <d-cite key="Parikh2014Proximal"></d-cite>.</p>

<p>The idea behind the proximal gradient method is to perform a gradient descent step assuming we are just going to be minimizing the smooth function $f$ and then do an evaluation of the proximal operator for $g$ which can be interpreted as a gradient descent step on the smoothed version of $g$. More technically we do a gradient descent step on the Moreau envelope of $g$.</p>

<p>Alternating between these two steps, we eventually minimize our original objective function.</p>

<p>For Lasso we will take,</p>

\[\begin{split}
    f(x) &amp;= \frac{1}{2}\|Ax-b\|_2^2 \\
    g(x) &amp;= \|x\|_1 \\
\end{split}\]

<p>It can be shown that the proximal operator for the l1 norm is the soft threshold operator</p>

\[\boldsymbol{\text{prox}}_{\eta \|\cdot\|_1}(v) = \mathcal{S}_\eta(v) = \text{sign}(v)\max(|v|-\eta,0)\]

<p>We can now write out the ISTA iterates as follows</p>

\[x_{k+1} = \mathcal{S}_{\lambda/L}\left(x_k - \frac{1}{L}A^\top(Ax_k-b)\right)\]

<p>Where $L$ is the maximum eigenvalue of $A^TA$. This can quickly be computed via <a href="https://en.wikipedia.org/wiki/Power_iteration" rel="external nofollow noopener" target="_blank">power iteration</a>.</p>

<p>It can be shown that this algorithm has a worst-case convergence rate of $\mathcal{O}(1 / t)$ meaning that if we double the number of iterations, we double the accuracy of the solution. This is already better than subgradient method, but is not the best we can do.</p>

<h2 id="fista">FISTA</h2>
<p>ISTA was used for a while, but many researchers noticed that it can be painfully slow to converge. In 2009, Beck and Teboulle introduced FISTA (Fast Iterative Shrinking Threshold Algorithm) where they used momentum to accelerate ISTA and were able to achieve the worst-case convergence rate of $\mathcal{O}(1 / t^2)$ , meaning that if we double the number of iterations, we quadruple the accuracy of the solution <d-cite key="Beck2009Fast"></d-cite>. FISTA can be thought of as applying ideas from <a href="https://web.archive.org/web/20210302210908/https://blogs.princeton.edu/imabandit/2013/04/01/acceleratedgradientdescent/" rel="external nofollow noopener" target="_blank">Nesterov’s Accelerated Gradient</a> to ISTA.</p>

<p>This algorithm can be written as follows</p>

\[\begin{align}
x_k &amp;= \mathcal{S}_{\lambda/L}\left(y_k - \frac{1}{L}A^\top(Ay_k-b)\right) \\
t_{k+1} &amp;= \frac{1+\sqrt{1+4t_k^2}}{2} \\
y_{k+1} &amp;= x_k + \left(\frac{t_k-1}{t_{k+1}}\right)(x_k-x_{k-1})
\end{align}\]

<h2 id="admm">ADMM</h2>
<p>The final algorithm we will consider for Lasso is the Alternating Direction Method of Multiplers (ADMM). This algorithm was introduced in the mid-1970s, but became popular again after Stephen Boyd <em>et al</em> published their paper in 2011 <d-cite key="Boyd2011-lv"></d-cite>. This algorithm attempts to solve problems of the following form</p>

\[\begin{split}
    \underset{x,z}{\text{minimize}} 
    \quad &amp; f(x) + g(z) \\
    \text{subject to} 
    \quad &amp; x = z, \\
\end{split}\]

<p>The iterates of the algorithm are as follows:</p>

\[\begin{align}
x_{k+1} &amp;= \underset{x}{\text{argmin}} \; \mathcal{L}_\rho(x,z_k,y_k)  \\
z_{k+1} &amp;= \underset{z}{\text{argmin}} \;\mathcal{L}_\rho(x_{k+1},z,y_k)  \\
y_{k+1} &amp;= y_k + \rho(x_{k+1}-z_{k+1})
\end{align}\]

<p>where</p>

\[\mathcal{L}_\rho(x,z,y) = f(x) + g(z) + y^T(x-z) + \frac{\rho}{2}\|x-z\|_2^2\]

<p>For the case of Lasso, we have</p>

\[\begin{align}
f(x) &amp;= \frac{1}{2}\|Ax-b\|_2^2 \\
g(z) &amp;= \|z\|_1
\end{align}\]

<p>and the ADMM iterates become</p>

\[\begin{align}
x_{k+1} &amp;= (A^TA+\rho I)^{-1}(A^Tb+\rho z_k -y_k)  \\
z_{k+1} &amp;= \mathcal{S}_{\lambda/\rho} (x_{k+1}+y_k/\rho)  \\
y_{k+1} &amp;= y_k + \rho(x_{k+1}-z_{k+1})
\end{align}\]

<p>Here, $\rho$ is a stepsize and it is not clear how to choose it optimally.</p>

<h2 id="results">Results</h2>
<p>Now we will test the QP version of Lasso, ISTA, FISTA, and ADMM to see which is fastest. To generate the data, I generated a random $A \in \mathbb{R}^{m \times n}$ with $m &lt; n$, then generated a random sparse vector $x_{*}$, and calculated $b=Ax_*$.</p>

<p>The stopping criteria for all solver was coming within $0.0001$ of the optimal objective function value.</p>

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/Ista-Fista-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/Ista-Fista-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/Ista-Fista-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/Ista-Fista.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture>

</figure>

    </div>
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/ADMM-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/ADMM-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/ADMM-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/ADMM.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture>

</figure>

    </div>
</div>
<div class="caption">
    Convergence of ISTA, FISTA, and ADMM with varying stepsizes
</div>

<table>
  <thead>
    <tr>
      <th>Algorithm</th>
      <th>Solve Time (sec)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>ADMM (rho=50)</td>
      <td>0.197</td>
    </tr>
    <tr>
      <td>ADMM (rho=100)</td>
      <td>0.202</td>
    </tr>
    <tr>
      <td>ADMM (rho=10)</td>
      <td>1.097</td>
    </tr>
    <tr>
      <td>FISTA</td>
      <td>1.652</td>
    </tr>
    <tr>
      <td>OSQP</td>
      <td>2.271</td>
    </tr>
    <tr>
      <td>ISTA</td>
      <td>8.880</td>
    </tr>
  </tbody>
</table>

<p>It should be mentioned that the ISTA, FISTA, and ADMM implementations are quite naive and unoptimized, but the OSQP solver is written is pure C.
The slowest algorithm by far is ISTA followed by reformulating Lasso as a QP and using OSQP, followed by FISTA, and the fastest algorithm was ADMM. The code to generate the plots can be found <a href="https://github.com/govindchari/blog-code/tree/main/lasso" rel="external nofollow noopener" target="_blank">here</a>.</p>

<hr>

      </d-article>

      <d-appendix>
        <d-footnote-list></d-footnote-list>
        <d-citation-list></d-citation-list>
      </d-appendix>

      <d-bibliography src="/assets/bibliography/mybib.bib"></d-bibliography>
</div>

    <!-- Footer -->    
    <footer class="fixed-bottom">
      <div class="container mt-0">
        © Copyright 2023 Govind M Chari. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>.

      </div>
    </footer>

    <!-- Bootsrap & MDB scripts -->
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script>

    
    

<!-- Scrolling Progress Bar -->
<script type="text/javascript">
  /*
   * This JavaScript code has been adapted from the article 
   * https://css-tricks.com/reading-position-indicator/ authored by Pankaj Parashar, 
   * published on the website https://css-tricks.com on the 7th of May, 2014.
   * Couple of changes were made to the original code to make it compatible 
   * with the `al-foio` theme.
   */
  const progressBar = $("#progress");
  /*
   * We set up the bar after all elements are done loading.
   * In some cases, if the images in the page are larger than the intended
   * size they'll have on the page, they'll be resized via CSS to accomodate
   * the desired size. This mistake, however, breaks the computations as the
   * scroll size is computed as soon as the elements finish loading.
   * To account for this, a minimal delay was introduced before computing the
   * values.
   */
  window.onload = function () {
    setTimeout(progressBarSetup, 50);
  };
  /*
   * We set up the bar according to the browser.
   * If the browser supports the progress element we use that.
   * Otherwise, we resize the bar thru CSS styling
   */
  function progressBarSetup() {
    if ("max" in document.createElement("progress")) {
      initializeProgressElement();
      $(document).on("scroll", function() {
        progressBar.attr({ value: getCurrentScrollPosition() });
      });
      $(window).on("resize", initializeProgressElement);
    } else {
      resizeProgressBar();
      $(document).on("scroll", resizeProgressBar);
      $(window).on("resize", resizeProgressBar);
    }
  }
  /*
   * The vertical scroll position is the same as the number of pixels that
   * are hidden from view above the scrollable area. Thus, a value > 0 is
   * how much the user has scrolled from the top
   */
  function getCurrentScrollPosition() {
    return $(window).scrollTop();
  }

  function initializeProgressElement() {
    let navbarHeight = $("#navbar").outerHeight(true);
    $("body").css({ "padding-top": navbarHeight });
    $("progress-container").css({ "padding-top": navbarHeight });
    progressBar.css({ top: navbarHeight });
    progressBar.attr({
      max: getDistanceToScroll(),
      value: getCurrentScrollPosition(),
    });
  }
  /*
   * The offset between the html document height and the browser viewport
   * height will be greater than zero if vertical scroll is possible.
   * This is the distance the user can scroll
   */
  function getDistanceToScroll() {
    return $(document).height() - $(window).height();
  }

  function resizeProgressBar() {
    progressBar.css({ width: getWidthPercentage() + "%" });
  }
  // The scroll ratio equals the percentage to resize the bar
  function getWidthPercentage() {
    return (getCurrentScrollPosition() / getDistanceToScroll()) * 100;
  }
</script>

  
</body>
</html>
