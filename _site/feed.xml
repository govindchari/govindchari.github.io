<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.1">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" hreflang="en" /><updated>2023-09-02T18:52:51-07:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">blank</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design.
</subtitle><entry><title type="html">Hypothesis Testing</title><link href="http://localhost:4000/blog/2023/hypo/" rel="alternate" type="text/html" title="Hypothesis Testing" /><published>2023-09-01T00:00:00-07:00</published><updated>2023-09-01T00:00:00-07:00</updated><id>http://localhost:4000/blog/2023/hypo</id><content type="html" xml:base="http://localhost:4000/blog/2023/hypo/"><![CDATA[<h2 id="introduction">Introduction</h2>
<p>Lets say you flip a coin ten times and it comes up heads six out of ten times. Would you think this coin is biased? Probably not.</p>

<p>Now lets say you flip a coin a thousand times and it comes up heads six hundred times. You would probably think it is biased. But why?</p>

<p>In both cases the coin comes up heads 60% of the time. How can we quantify our intuition here? We will turn to the world of hypothesis testing to answer this question.</p>

<h2 id="null-and-alternative-hypothesis">Null and Alternative Hypothesis</h2>

<p>The null hypothesis is the statement we are trying develop evidence against and the alternative hypothesis is its compliment.</p>

<p>Here our null hypothesis is that the coin is fair. The alternative hypothesis is that the coin is biased.</p>

<h2 id="p-value">P-Value</h2>
<p>One useful question for us to ask is what is the chance that we see an event this or more extreme due to random chance assuming the coin where unbiased?</p>

<p>The statistical term for this is p-value.</p>

<p>If our p-value is small it means that it is unlikely that we saw six hundred heads out of one thousand flips coming up heads if the coin were fair. So a smaller p-value would make us conclude that the coin is indeed biased.</p>

<h2 id="level-of-significance">Level of Significance</h2>
<p>But how small of a p-value is small enough for us to conclude the coin is biased? In statistics, this value is called $\alpha$ and a typical value for $\alpha$ is 0.05. But what does this $\alpha$ really mean?</p>

<p>It is the chance that we conclude that the coin is biased when in reality it isn’t. This kind of error is called type I error.</p>

<p>So if $p &lt; 0.05$ then we will conclude that the coin is biased, and we know there is a 5% chance that we conclude the coin is biased when in reality it is not.</p>

<h2 id="example">Example</h2>
<p>Let’s dig into the math of computing p-values. By definition, the p-value is the chance that we see six hundred or more heads out of a thousand flips assuming the coin where unbiased.</p>

<p>Let $X$ be a <a href="https://en.wikipedia.org/wiki/Bernoulli_distribution">Bernoulli</a> random variable. If $X=0$ then the coin landed on tails, and if $X=1$ the coin landed on heads. Since we are assuming the coin is unbiased we can write the probability mass function, expected value, and variance of $X$ as follows</p>

\[\mathbb{P}[X=0] = 0.5\]

\[\mathbb{P}[X=1] = 0.5\]

\[\mathbb{E}[X] = 0.5\]

\[\mathbb{V}[X] = 0.25\]

<p>The number of heads that we get is the sum of X from 1 to a thousand. We will define this new random variable as $H$. We can write its expected value and variance as follows</p>

\[\mathbb{E}[H] = 500\]

\[\mathbb{V}[H] = 250\]

<p>Since H is the sum of a large number of independent and identically distrubuted random variables, we can use the <a href="https://www.youtube.com/watch?v=zeJD6dqJ5lo&amp;ab_channel=3Blue1Brown">central limit theorem</a> to conclude that in addition to having the expected value and variance written above we know that $H$ is normally distributed. We can then calculate the <a href="https://en.wikipedia.org/wiki/Standard_score">z-score</a> of flipping 6 million heads as follows:</p>

\[z = \frac{x-\mu}{\sigma} = \frac{600 - \mathbb{E}[H]}{\sqrt{\mathbb{V}[H]}} \approx 6.32\]

<p>To get the p-value from the z-score we use the standard gaussian cumulative density function as follows:</p>

\[p = 2(1 - \phi(z)) \approx 2 \times 10^{-10}\]

<p>This p-value is less than 0.05 so we can conclude that the coin is biased.</p>

<h2 id="code">Code</h2>
<p>Below is some Julia code that conducts a hypothesis test for a coin flip example. The input parameters are the number of heads and the number of coin flips. The source file can be found <a href="https://github.com/govindchari/blog-code/blob/main/statistics/hypothesis_testing.jl">here</a>. I encourage you to play around with the number of heads and total number of flips to get an intuition for what is statistically significant and what isn’t.</p>

<figure class="highlight"><pre><code class="language-julia" data-lang="julia"><span class="k">using</span> <span class="n">Distributions</span>

<span class="c"># Input Parameters</span>
<span class="n">num_heads</span> <span class="o">=</span> <span class="mi">60</span>
<span class="n">num_flips</span> <span class="o">=</span> <span class="mi">100</span>
<span class="nd">@assert</span> <span class="n">num_heads</span> <span class="o">&lt;=</span> <span class="n">num_flips</span> <span class="s">"Number of heads must be less than or equal to the number of flips"</span>

<span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.05</span> <span class="c"># Significance level</span>

<span class="c"># Mean and variance of number of heads if the coin were unbiased</span>
<span class="n">mu</span> <span class="o">=</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">num_flips</span>
<span class="n">var</span> <span class="o">=</span> <span class="mf">0.25</span> <span class="o">*</span> <span class="n">num_flips</span>

<span class="c"># Z-Score of our observation of num_heads</span>
<span class="n">z</span> <span class="o">=</span> <span class="x">(</span><span class="n">num_heads</span> <span class="o">-</span> <span class="n">mu</span><span class="x">)</span> <span class="o">/</span> <span class="n">sqrt</span><span class="x">(</span><span class="n">var</span><span class="x">)</span>

<span class="c"># Compute p-value</span>
<span class="n">p</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="x">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">cdf</span><span class="x">(</span><span class="n">Normal</span><span class="x">(),</span> <span class="n">abs</span><span class="x">(</span><span class="n">z</span><span class="x">)))</span>

<span class="n">println</span><span class="x">(</span><span class="s">"p-value: "</span><span class="x">,</span> <span class="n">p</span><span class="x">)</span>
<span class="k">if</span> <span class="x">(</span><span class="n">p</span> <span class="o">&lt;</span> <span class="n">alpha</span><span class="x">)</span>
    <span class="n">println</span><span class="x">(</span><span class="s">"p &lt; 0.05 so we can reject the null hypothesis and conclude the coin is biased"</span><span class="x">)</span>
<span class="k">else</span>
    <span class="n">println</span><span class="x">(</span><span class="s">"p &gt; 0.05 so we cannot reject the null hypothesis and we cannot conclude that the coin is biased"</span><span class="x">)</span>
<span class="k">end</span></code></pre></figure>

<hr />]]></content><author><name>Govind Chari</name></author><category term="math" /><summary type="html"><![CDATA[Testing for statistical significance]]></summary></entry><entry><title type="html">Convex Solvers</title><link href="http://localhost:4000/blog/2023/optimization-algorithms/" rel="alternate" type="text/html" title="Convex Solvers" /><published>2023-02-03T00:00:00-08:00</published><updated>2023-02-03T00:00:00-08:00</updated><id>http://localhost:4000/blog/2023/optimization-algorithms</id><content type="html" xml:base="http://localhost:4000/blog/2023/optimization-algorithms/"><![CDATA[<h2 id="introduction">Introduction</h2>

<p>Convex optimization is a class of optimization concerned with minimizing a convex function over a convex set. 
One important feature of convex optimization is that any local minimum for a convex problem is the global minimum,
this means that the global minimum can be found very quickly. Mathamatically, a convex problem can be written as follows</p>

\[\begin{align*}
\min_{x} &amp; \; f(x) \\
\textrm{s.t.} &amp; \; h_{i}(x) = 0, \quad i = 1, \ldots, m \\
&amp; \; g_{i}(x) \leq 0, \quad i = 1, \ldots, p
\end{align*}\]

<p>where $x \in \mathbb{R}^n$ is the optimization variable, $f(x)$ is a convex objective function, $h_{i}(x)=0$ are affine equality
constraints, and $g_{i}(x) \leq 0$ are convex inequality constraints.</p>

<p>This post focuses on stressing the intuition of different classes of convex solver and provides references for further reading at the end of each section.</p>

<hr />

<h2 id="active-set-methods">Active Set Methods</h2>
<p>A constraint is said to be active at a point $x_0$ if $g_i(x_0) = 0$. We can define the optimal active set as the set of all constraints that are active at the optimal solution $x^*$. We can see that all the equality constraints will be in the optimal active set.</p>

<p>Active set methods take advantage of the fact that equality constrainted problems are easier to solve than inequality constrainted problems. These methods start with a guess of the optimal active set and solve this equality constrained subproblem. Then it uses information from the solution of the subproblem, for example the sign of the dual variables, to add and remove constraints from the current guess of the active set.</p>

<p>If a good guess of the optimal active set is known, these methods can be be very fast and only take a handful of iterations. As a result these methods warmstart well and would be advantageous in applications like model predictive control since it is is unlikely that the optimal active set drastically changes between two solves.</p>

<p>The disadvantage of active set methods is that the theoretical worst-case runtime is exponential in the number of constraints since in the worst case, all combinations of constraints must be tested.</p>

<p>One famous example of an active set algorithm is Simplex, which was invented by George Dantzig for Linear Programs (LPs). In Simplex, all iterates are vertices of the feasible set (which is a polytope), however this is not the case for quadratic programs (QPs) or any more complex optimization problem. Another active set solver is <a href="https://github.com/coin-or/qpOASES">qpOASES</a>.</p>

<p>Each iteration of an active set method for QPs solves an equality constrained QP. Now we will see how equality constrained QPs can be solved in a simple way. For equality constrained QPs, the KKT conditions which are necessary and sufficient conditions for optimality are linear and thus they can be solved in one Newton step. We can write the equality constrained QP as follows where $Q&gt;0$.</p>

\[\begin{align*}
\min_{x} &amp; \; \frac{1}{2}x^\top Qx + q^\top x \\
\textrm{s.t.} &amp; \; Ax=b\\
\end{align*}\]

<p>we can write the KKT conditions for this problem as follows, where $\lambda$ is a vector of dual variables</p>

\[\begin{align*}
Qx+q+A^\top \lambda &amp;= 0 \\
Ax-b &amp;= 0
\end{align*}\]

<p>We can see that this system of equations is linear in the primal and dual variables so we can find the optimal primal and dual solution by solving the following system
of equations</p>

\[\begin{bmatrix}
Q &amp; A^\top \\
A &amp; 0
\end{bmatrix}
\begin{bmatrix}
x \\
\lambda
\end{bmatrix} = 
\begin{bmatrix}
-q \\
b
\end{bmatrix}\]

<p>Thus we can see that solving the equality constrained quadratic program amounts to nothing more than solving a linear system.</p>

<p>To learn more about the details of active set methods reference Chapter 16 Section 5 of <em>Numerical Optimization</em> by Nocedal and Wright.</p>

<hr />

<h2 id="interior-point-methods-ipms">Interior Point Methods (IPMs)</h2>

<p>As the name suggests, interior point methods solve optimization problems in a way that the iterates lie in the interior of the feasible set. There are two main variants of IPMs: primal and primal-dual. In primal IPMs, we only compute iterates of the primal variables, and in primal-dual IPMs we compute iterates of both the primal and dual variables.</p>

<p>Primal IPMs make use of the fact that the following two problems are equivalent:</p>

\[\begin{align*}
\min_{x} &amp; \; f(x) \\
\textrm{s.t.} &amp; \; x \in \mathcal{D}\\
\end{align*}\]

<p>where $\mathcal{D}$ is some convex set and</p>

\[\begin{align*}
\min_{x} &amp; \; f(x) + \mathcal{I}_{\mathcal{D}}(x)\\
\end{align*}\]

<p>where $\mathcal{I}_{\mathcal{D}}(x)$ is the indicator function on $\mathcal{D}$ which is defined as</p>

\[\mathcal{I}_{\mathcal{D}}(x) = 

\begin{cases}
0 &amp; \text{if} \; x \in \mathcal{D} \\
\infty &amp; \text{if} \; x \notin \mathcal{D}

\end{cases}\]

<p>However, we cannot directly solve the minimization problem with the indicator function since it is nonsmooth at the boundary of the set $\mathcal{D}$, since it jumps from some finite value to infinity. This primal IPMs seek to replace the indicator function with a smooth approximation called a log-barrier function. This log-barrier function is roughly zero when $x \in \mathcal{D}$ and steeply approches infinity when you approach the boundary of $\mathcal{D}$.</p>

<p>This steepness is controlled by a “barrier parameter.” The steeper the barrier function is, the better it approximates the indicator function, but the less smooth and worse conditioned the minimization becomes. Initially the unconstrained problem is solved with a shallow barrier parameter and then is successively solved with steeper and steeper barrier parameters. This barrier can be thought of as a force-field that pushes the iterates away from the boundary of the feasible set and amount that this force field pushes the iterates is controlled by the barrier paramter.</p>

<p>Primal-Dual IPMs take a slightly different approach. They attempt to use Newton’s method on the KKT conditions of the problem with some other fancy tricks such as taking a prediction step then a correction step which allows the algorithm to reuse the factorization of the KKT matrix. This famed trick is called Mehrotra’s Predictor-Corrector. The Primal Dual IPM is famously used by SpaceX in their rocket landing algorithm <d-cite key="Blackmore2016Autonomous"></d-cite>, <d-cite key="Mattingley2011CVXGEN"></d-cite>.</p>

<p>One large drawback to using IPMs in real-time systems is the fact that they cannot be warmstarted which is a desirable property of real-time solvers.</p>

<p>One example of an IPM is <a href="https://github.com/embotech/ecos">ECOS</a>.</p>

<p>To learn more about primal IPMs reference Chapter 11 in <em>Convex Optimization</em> by Boyd and Vanderberghe and to learn more about primal-dual IPMs reference Chapter 14 and Chapter 16 Section 6 in Nocedal and Wright.</p>

<hr />

<h2 id="first-order-methods">First-Order Methods</h2>

<p>Both Active Set methods and IPMs typically rely on “second-order” information. Second order information is the information about the curvature of a function which is given by its second derivative, or for the multivariable case its Hessian. Using second order information allows these methods to converge quickly in few iterations, but each iteration requires the factorization of a large matrix which is a very expensive operation.</p>

<p>The number of floating point operations for matrix factorization scales with $\mathcal{O}(n^3)$ and storing the Hessian scales with $\mathcal{O}(n^2)$ where $n$ is the number of variables in your problem.</p>

<p>First Order methods on the other hand only use first-order information, which is information about the slope of a function which is given by its first derivative, or gradient in the multivariable case. First-order methods do not require matrix factorizations at each iteration and only require Matrix-vector multiplications. The number of floating point operations for matrix-vector multiplication scales with $\mathcal{O}(n^2)$, thus each iteration of a first-order method can be done quicker than an iteration of a second order method, but first order methods require more iterations to converge, since each iteration uses less information.</p>

<p>First order methods are more or less gradient descent algorithms with some modifications to handle constraints such as projections. For extremely large scale problems first order methods are preferable due to the high cost of factorizing and storing large matrices. However, even for medium sized problems we can gain a lot of performance from first-order methods by customizing the algorithm to the specific problem structure. For a detailed description of customization refer to <d-cite key="Kamath2023Customized"></d-cite>.</p>

<p>All of this performance of first order methods does have some drawbacks. First order methods are extremely sensitive to ill conditioned objectives and badly scaled problem data. Thus an extrememly fast and robust implementation of a first-order method must scale the problem data, precondition the problem, and be customized to the problem structure. Without customization the algorithm will still be very fast (around the same speed as IPMs), but customization allows the full speed of the algorithm to be unlocked. To see some speed results of a particular first order algorithm called PIPG, refer to <d-cite key="Kamath2023Customized"></d-cite>, <d-cite key="Yu2022Extrapolated"></d-cite>. These papers have results that show that PIPG is faster than ECOS, SCS, MOSEK, Gurobi, and OSQP once customized and preconditioned.</p>

<p>Some examples of first order solvers are <a href="https://osqp.org/">OSQP</a>, <a href="https://github.com/cvxgrp/scs">SCS</a>, and PIPG.</p>

<h2 id="summary">Summary</h2>

<p>Here we will quickly sumamrize the advantages and disadvantages of each method.</p>

<p><strong>Active Set</strong></p>

<p>Advantages: Easy to warmstart, fast if you have a good guess for the active set</p>

<p>Disadvantages: Worse case exponential runtime in the number of constraints, bad for large problems</p>

<p><strong>IPMs</strong></p>

<p>Advantages: Fast and robust for medium sized problems</p>

<p>Disadvantages: Bad for large problems, cannot warmstart, large code footprint</p>

<p><strong>First-Order</strong></p>

<p>Advantages: Small code footprint, good for large problems, can be good for medium sized problems with customization, ease of customization, easy to warmstart</p>

<p>Disadvantages: Highly sensitive to scaling and conditioning so they need scaling and preconditioning</p>

<hr />]]></content><author><name>Govind Chari</name></author><category term="math" /><summary type="html"><![CDATA[A survey of the different classes of solvers for convex optimization problems]]></summary></entry></feed>